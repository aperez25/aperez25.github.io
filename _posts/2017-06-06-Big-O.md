---
published: true
---
## O-M-G

Big O can be intimidating when you don't come from a technical background and see phrases like "time or space complexity." I definitely was scratching my head going "huh?" when I was first introduced to it. Here I'll breakdown some of the phrases you'll see for determining time complexity specifically and what they mean in plain English. 

**TLDR: Big O answers the question, "How much time or space does the algorithm [i.e. function we're working with] take as our input gets bigger?"**

...So what does bigger mean?

In general, this is saying what happens to the function when our the argument gets larger; maybe our array grows from 10 to 10,000 elements, or our number grows to a higher magnitude (10 to 10,000,000), or the number of distinct elements we're evaluating goes up.

## Order of Magniude (not as big of a deal as you think)
When you see "Order of Magnitude" for Big O, you want to think broadly. We're not trying to figure out how fast a function runs on a specific computer. We could benchmark it to discover the concrete cost, but that is hard to determine beforehand. So, we're looking for a pattern that's easier to figure out, i.e.:

What is the _shape_ of the growth curve for this function in general? [You can see a great chart of here.](http://bigocheatsheet.com/)

Here are common Big O notations noted from best to worst: 
- `O(1)`: constant
- `O(log(n))`: logarithmic 
- `O(n)`: linear
- `O(n * log(n))`: log-linear
- `O(n^2)`: quadratic 
- `O(2^n)`: exponential 
- `O(n!)`: factorial

## Curves?! Give it to me straight
The growth curve's shape is the _upper bound_. In general, you want to find the worst case scenario for any given function (there are some exceptions where we want a typical scenario but I won't get into it here). For example, if we had something like this and we wanted to get the time complexity:

```js
function logElements (arr) {
	arr.forEach(element =>
    console.log element) 
    })
}
```

We would go through the function step-by-step and see what's going on: 

```js
function logElements (arr) {
	// The forEach method goes through each element n, so the run time here depends on the length of the array, i.e. how many n elements we have. This gives us: O(n)
	arr.forEach(element => 
    // console.log is a side effect of our function, so we say this runs at a constant time: O(1)
    console.log element) => O(1)
    })
}
```

We then take all of the run times and add these together: `O(n) + O(1) => O(n + 1)`

Then take a step back. Will we really care about one when our `n` is 10 million? 10 billion? Nope, because one is tiny when compared to `n` at that point. So we can just drop the one. For Big O, we only care about the stuff that grows the fastest because it gives us the shape of the curve. 

So for `logElements` we have a Big O of O(n), where n is referring to the length of the array. So, n (or whatever variable you use) is defined on a per-problem basis. 

## Why should you care? 
O(n) gives us accuracy. We're saying, for logElements, no matter what the input is, the performance will never be better than O(n). 

If we're okay with that worst case scenario, than we're definitely okay with the average runtime case and with the best case for our function. 

Again, Big O is not a concrete measurement of time or space, but some kind of curve. The curves for functions give us a way to compare algorithms.

## General procedure for finding Big O
Let me preface this with a disclaimer: there is no definitive way to find Big O, but this is a  loose approach we can use. This is why you'll read about people stressing about algorithm  interview questions. There isn't a foolproof system, only a lot of practice involved. So, what can we do to get started?

- Count the steps:
	- Is there nesting?
    	- Anytime you hit a loop, multiply (the number of iterations) * (max complexity of internals) 
        	- Max complexity of internals: the run times for what's inside the loop block
    - Siblings: take the biggest one, forget the rest (like in `logElements`)
  - Drop constants
  - Drop lower-order (smaller exponent) terms
  - RAM model [hypothetical computer](https://www8.cs.umu.se/kurser/TDBA77/VT06/algorithms/BOOK/BOOK/NODE12.HTM): 
	- Simple operations are constant: 
    	- assignment/declaration
        - operators (boolean, arithmetic)
        - control flow(if / else, ternary, etc.)
        - side effects(logging, input, etc) 
        - SOMETIMES, return statements 
    - Loops: see first bullet on nesting 
    - Function calls: need to know their Big O or analyze function body 
    	- some general guidance: if the function doesn't take an input, it's runtime must be O(1) since there isn't anything that can change it's runtime
- Evaluating all of the steps: 
  - Big O is associative i.e. operations can be chained together, as you may have already noticed!
      - O(a) + O(b) = O(a + b) 
      - O(a) * O(b) = O(a * b)

## Putting it all together
```js
// O(?) n = arr.length
function shuffle (arr) { 
    var last, rand, temp, // O(1)
        i = arr.length; // O(1) 
    while (i--) { // O(n) * O(1) [from the assignments inside the loop]
        last = arr[i] // O(1)
        rand = Math.floor(Math.random() * i) // O(1)
        temp = arr[i] // O(1)
        arr[i] = arr[rand] // O(1)
        arr[rand] = temp // O(1)
    }
    return arr; // O(1)
}

```

Have you figured it out?....

For our function shuffle, `O(1) + O(1) + O(n) + O(1)` gives us....`O(n)`! 

